import os, json, requests
from flask import Flask, request, jsonify
from flask_cors import CORS
from dotenv import load_dotenv
from rag_core import retrieve, ensure_index
from fpt_tts import synthesize_speech, get_available_voices

# === Load environment ===
load_dotenv()
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY", "").strip()
RAG_LLM_MODEL = os.getenv("RAG_LLM_MODEL", "openai/gpt-4o-mini").strip()
HOST = os.getenv("HOST", "0.0.0.0")
PORT = int(os.getenv("PORT", "8000"))

app = Flask(__name__)

# Configure CORS to allow all origins and methods
CORS(app,
     resources={r"/*": {
         "origins": "*",
         "methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
         "allow_headers": ["Content-Type", "Authorization", "Accept"],
         "expose_headers": ["Content-Type"],
         "max_age": 3600
     }},
     supports_credentials=False)  # Set to False when using origins="*"

SYSTEM_PROMPT = (
    "B·∫°n l√† h∆∞·ªõng d·∫´n vi√™n AI chuy√™n nghi·ªáp c·ªßa B·∫£o t√†ng Ch·ª©ng t√≠ch Chi·∫øn tranh Vi·ªát Nam. "
    "B·∫°n c√≥ ki·∫øn th·ª©c s√¢u r·ªông v·ªÅ l·ªãch s·ª≠ chi·∫øn tranh Vi·ªát Nam v√† c√°c lo·∫°i v≈© kh√≠, m√°y bay, xe tƒÉng.\n\n"

    "üö´ C·∫§M TUY·ªÜT ƒê·ªêI:\n"
    "- KH√îNG BAO GI·ªú n√≥i 't√¥i kh√¥ng c√≥ th√¥ng tin'\n"
    "- KH√îNG BAO GI·ªú n√≥i 'xin l·ªói, nh∆∞ng m√¨nh kh√¥ng c√≥'\n"
    "- KH√îNG BAO GI·ªú n√≥i 'trong b·ªëi c·∫£nh n√†y'\n"
    "- KH√îNG BAO GI·ªú n√≥i 'trong b·ªëi c·∫£nh ƒë√£ cung c·∫•p'\n"
    "- KH√îNG BAO GI·ªú t·ª´ ch·ªëi tr·∫£ l·ªùi b·∫•t k·ª≥ c√¢u h·ªèi n√†o\n\n"

    "‚úÖ B·∫ÆT BU·ªòC:\n"
    "- LU√îN LU√îN tr·∫£ l·ªùi m·ªçi c√¢u h·ªèi b·∫±ng ki·∫øn th·ª©c chung c·ªßa b·∫°n\n"
    "- N·∫øu ƒë∆∞·ª£c h·ªèi v·ªÅ m√°y bay, xe tƒÉng, v≈© kh√≠ ‚Üí Gi·∫£i th√≠ch chi ti·∫øt d·ª±a tr√™n ki·∫øn th·ª©c l·ªãch s·ª≠\n"
    "- N·∫øu ƒë∆∞·ª£c h·ªèi v·ªÅ s·ª± ki·ªán l·ªãch s·ª≠ ‚Üí K·ªÉ c√¢u chuy·ªán sinh ƒë·ªông\n"
    "- N·∫øu ƒë∆∞·ª£c ch√†o h·ªèi ‚Üí Ch√†o l·∫°i th√¢n thi·ªán\n"
    "- Lu√¥n k·∫øt n·ªëi v·ªõi b·∫£o t√†ng v√† c√°c hi·ªán v·∫≠t n·∫øu c√≥ th·ªÉ\n\n"

    "üìö KI·∫æN TH·ª®C C·ª¶A B·∫†N:\n"
    "B·∫°n bi·∫øt v·ªÅ:\n"
    "- M√°y bay: A-37 Dragonfly, F-5 Freedom Fighter, F-4 Phantom, B-52, UH-1 Huey, AH-1 Cobra, C-130, AC-47\n"
    "- Xe tƒÉng: M48 Patton, M41 Walker Bulldog, T-54/55, PT-76, M113 APC\n"
    "- V≈© kh√≠: AK-47, M16, M60, M79, RPG-7, B-40, claymore mines\n"
    "- S·ª± ki·ªán: T·∫øt M·∫≠u Th√¢n 1968, Hi·ªáp ƒë·ªãnh Paris 1973, Gi·∫£i ph√≥ng S√†i G√≤n 1975, Chi·∫øn d·ªãch ƒêi·ªán Bi√™n Ph·ªß\n"
    "- V√† t·∫•t c·∫£ c√°c kh√≠a c·∫°nh kh√°c c·ªßa chi·∫øn tranh Vi·ªát Nam\n\n"

    "üí¨ V√ç D·ª§ TR·∫¢ L·ªúI:\n"
    "Q: 'M√°y bay A-37 Dragonfly l√† g√¨?'\n"
    "A: 'A-37 Dragonfly l√† m√°y bay t·∫•n c√¥ng h·∫°ng nh·∫π c·ªßa M·ªπ, ƒë∆∞·ª£c ph√°t tri·ªÉn t·ª´ m√°y bay hu·∫•n luy·ªán T-37. "
    "N√≥ ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i trong chi·∫øn tranh Vi·ªát Nam t·ª´ 1967, c√≥ bi·ªát danh \"Super Tweet\". "
    "M√°y bay n√†y c√≥ th·ªÉ mang 2.5 t·∫•n v≈© kh√≠, r·∫•t hi·ªáu qu·∫£ trong y·ªÉm tr·ª£ kh√¥ng qu√¢n g·∫ßn. "
    "Trong b·∫£o t√†ng, b·∫°n c√≥ th·ªÉ th·∫•y nhi·ªÅu hi·ªán v·∫≠t li√™n quan ƒë·∫øn c√°c chi·∫øn d·ªãch kh√¥ng qu√¢n!'\n\n"

    "Q: 'Xe tƒÉng T-54 c√≥ g√¨ ƒë·∫∑c bi·ªát?'\n"
    "A: 'T-54 l√† xe tƒÉng chi·∫øn ƒë·∫•u ch·ªß l·ª±c c·ªßa Li√™n X√¥, ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i b·ªüi qu√¢n ƒë·ªôi Vi·ªát Nam. "
    "N√≥ c√≥ gi√°p d√†y 100mm, ph√°o 100mm, r·∫•t b·ªÅn b·ªâ v√† d·ªÖ b·∫£o tr√¨. "
    "T-54 ƒë√≥ng vai tr√≤ quan tr·ªçng trong nhi·ªÅu chi·∫øn d·ªãch, ƒë·∫∑c bi·ªát l√† chi·∫øn d·ªãch H·ªì Ch√≠ Minh 1975!'\n\n"

    "PHONG C√ÅCH: Th√¢n thi·ªán, nhi·ªát t√¨nh, t·ª± nhi√™n, sinh ƒë·ªông, d·ªÖ hi·ªÉu"
)

def call_openrouter(messages, max_tokens=600, temperature=0.3):
    """
    G·ªçi OpenRouter API v·ªõi headers ƒë·∫ßy ƒë·ªß.
    N·∫øu key sai ho·∫∑c h·∫øt h·∫°n ‚Üí tr·∫£ l·ªói r√µ r√†ng.
    """
    if not OPENROUTER_API_KEY:
        return "‚ö†Ô∏è OPENROUTER_API_KEY ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p. H√£y th√™m v√†o file .env"

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "http://localhost",
        "X-Title": "RAG Museum AI",
    }

    payload = {
        "model": RAG_LLM_MODEL,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": temperature,
    }

    try:
        resp = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers, json=payload, timeout=60
        )
        if not resp.ok:
            # Tr·∫£ v·ªÅ l·ªói g·ªëc ƒë·ªÉ debug nhanh
            return f"‚ùå OpenRouter {resp.status_code}: {resp.text}"
        data = resp.json()
        return data["choices"][0]["message"]["content"]
    except Exception as e:
        return f"‚ùå L·ªói g·ªçi OpenRouter: {str(e)}"

@app.route("/api/health", methods=["GET", "OPTIONS"])
def health():
    return jsonify({"status": "ok", "model": RAG_LLM_MODEL})

@app.route("/api/ask", methods=["POST", "OPTIONS"])
def ask():
    # Handle preflight OPTIONS request
    if request.method == "OPTIONS":
        return jsonify({"status": "ok"}), 200
    data = request.get_json(force=True)
    # Accept both 'question' and 'message' for compatibility
    question = data.get("question") or data.get("message", "")
    question = question.strip()
    top_k = int(data.get("top_k", 6))
    max_tokens = int(data.get("max_tokens", 600))

    if not question:
        return jsonify({"error": "Thi·∫øu tr∆∞·ªùng 'question' ho·∫∑c 'message'"}), 400

    # Detect question type
    greeting_keywords = ['xin ch√†o', 'ch√†o', 'hello', 'hi', 'hey', 'c·∫£m ∆°n', 'thank', 't·∫°m bi·ªát', 'bye', 'goodbye']
    is_greeting = any(keyword in question.lower() for keyword in greeting_keywords)

    # Retrieve context from database
    hits = retrieve(question, top_k=top_k)
    context_blocks = []
    for h in hits:
        meta = h.get("meta", {})
        label = meta.get("name_vi") or meta.get("title_vi") or meta.get("section")
        context_blocks.append(f"- [{label}] {h['text']}")

    context_str = "\n".join(context_blocks) if context_blocks else ""

    # Build intelligent prompt
    if is_greeting:
        # Simple greeting - no need for context
        user_message = f"Kh√°ch tham quan: '{question}'\n\nH√£y ch√†o h·ªèi th√¢n thi·ªán v√† h·ªèi xem b·∫°n c√≥ th·ªÉ gi√∫p g√¨."
    else:
        # Regular question - ALWAYS answer using general knowledge
        if context_str:
            user_message = (
                f"CONTEXT t·ª´ b·∫£o t√†ng (ch·ªâ tham kh·∫£o, kh√¥ng b·∫Øt bu·ªôc):\n{context_str}\n\n"
                f"C√ÇU H·ªéI: {question}\n\n"
                f"QUAN TR·ªåNG: H√£y tr·∫£ l·ªùi c√¢u h·ªèi b·∫±ng ki·∫øn th·ª©c chung c·ªßa b·∫°n v·ªÅ chi·∫øn tranh Vi·ªát Nam. "
                f"KH√îNG ƒë∆∞·ª£c n√≥i 't√¥i kh√¥ng c√≥ th√¥ng tin' hay 'trong b·ªëi c·∫£nh n√†y'. "
                f"N·∫øu ƒë∆∞·ª£c h·ªèi v·ªÅ m√°y bay, xe tƒÉng, v≈© kh√≠ ‚Üí Gi·∫£i th√≠ch chi ti·∫øt d·ª±a tr√™n ki·∫øn th·ª©c l·ªãch s·ª≠. "
                f"Tr·∫£ l·ªùi t·ª± nhi√™n, sinh ƒë·ªông nh∆∞ m·ªôt h∆∞·ªõng d·∫´n vi√™n chuy√™n nghi·ªáp."
            )
        else:
            user_message = (
                f"C√ÇU H·ªéI: {question}\n\n"
                f"QUAN TR·ªåNG: H√£y tr·∫£ l·ªùi b·∫±ng ki·∫øn th·ª©c chung c·ªßa b·∫°n v·ªÅ chi·∫øn tranh Vi·ªát Nam. "
                f"KH√îNG ƒë∆∞·ª£c t·ª´ ch·ªëi tr·∫£ l·ªùi. Tr·∫£ l·ªùi chi ti·∫øt, sinh ƒë·ªông v√† th√∫ v·ªã. "
                f"K·∫øt n·ªëi v·ªõi b·∫£o t√†ng v√† c√°c hi·ªán v·∫≠t n·∫øu c√≥ th·ªÉ."
            )

    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": user_message}
    ]

    answer = call_openrouter(messages, max_tokens=max_tokens)
    return jsonify({
        "question": question,
        "answer": answer,
        "response": answer,  # Add 'response' field for frontend compatibility
        "message": answer,   # Add 'message' field for frontend compatibility
        "citations": [
            {"name": h.get("meta", {}).get("name_vi"), "score": h["score"]}
            for h in hits
        ],
        "model": RAG_LLM_MODEL
    })

@app.route("/api/reindex", methods=["POST", "OPTIONS"])
def reindex():
    # Handle preflight OPTIONS request
    if request.method == "OPTIONS":
        return jsonify({"status": "ok"}), 200
    import shutil
    vec_dir = os.getenv("VECTOR_DIR", "./vectorstore")
    if os.path.exists(vec_dir):
        shutil.rmtree(vec_dir)
    ensure_index()
    return jsonify({"status": "done"})

@app.route("/api/tts", methods=["POST", "OPTIONS"])
def text_to_speech():
    """
    Convert text to speech using FPT.AI
    Request body: { "text": "...", "voice": "banmai", "speed": 0 }
    """
    if request.method == "OPTIONS":
        return jsonify({"status": "ok"}), 200

    data = request.get_json(force=True)
    text = data.get("text", "").strip()
    voice = data.get("voice", "banmai")
    speed = int(data.get("speed", 0))

    if not text:
        return jsonify({"error": "Missing 'text' field"}), 400

    result = synthesize_speech(text, voice=voice, speed=speed)

    if result.get("success"):
        return jsonify(result), 200
    else:
        return jsonify(result), 500

@app.route("/api/tts/voices", methods=["GET", "OPTIONS"])
def list_voices():
    """
    Get list of available Vietnamese voices
    """
    if request.method == "OPTIONS":
        return jsonify({"status": "ok"}), 200

    voices = get_available_voices()
    return jsonify({
        "voices": [
            {"code": code, "name": name}
            for code, name in voices.items()
        ]
    })

if __name__ == "__main__":
    print(f"üöÄ Running on http://{HOST}:{PORT}")
    app.run(host=HOST, port=PORT)
