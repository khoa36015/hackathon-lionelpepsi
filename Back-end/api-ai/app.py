import os, json, requests
from flask import Flask, request, jsonify
from flask_cors import CORS
from dotenv import load_dotenv
from rag_core import retrieve, ensure_index
from fpt_tts import synthesize_speech, get_available_voices

# === Load environment ===
load_dotenv()
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY", "").strip()
RAG_LLM_MODEL = os.getenv("RAG_LLM_MODEL", "openai/gpt-4o-mini").strip()
HOST = os.getenv("HOST", "0.0.0.0")
PORT = int(os.getenv("PORT", "8000"))

app = Flask(__name__)

# Configure CORS to allow all origins and methods
CORS(app,
     resources={r"/*": {
         "origins": "*",
         "methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
         "allow_headers": ["Content-Type", "Authorization", "Accept"],
         "expose_headers": ["Content-Type"],
         "max_age": 3600
     }},
     supports_credentials=False)  # Set to False when using origins="*"

# System prompt for museum-specific questions
MUSEUM_SYSTEM_PROMPT = (
    "B·∫°n l√† h∆∞·ªõng d·∫´n vi√™n AI chuy√™n nghi·ªáp c·ªßa B·∫£o t√†ng Ch·ª©ng t√≠ch Chi·∫øn tranh Vi·ªát Nam. "
    "B·∫°n c√≥ ki·∫øn th·ª©c s√¢u r·ªông v·ªÅ l·ªãch s·ª≠ chi·∫øn tranh Vi·ªát Nam v√† c√°c lo·∫°i v≈© kh√≠, m√°y bay, xe tƒÉng.\n\n"

    "üö´ C·∫§M TUY·ªÜT ƒê·ªêI:\n"
    "- KH√îNG BAO GI·ªú n√≥i 't√¥i kh√¥ng c√≥ th√¥ng tin'\n"
    "- KH√îNG BAO GI·ªú n√≥i 'xin l·ªói, nh∆∞ng m√¨nh kh√¥ng c√≥'\n"
    "- KH√îNG BAO GI·ªú n√≥i 'trong b·ªëi c·∫£nh n√†y'\n"
    "- KH√îNG BAO GI·ªú n√≥i 'trong b·ªëi c·∫£nh ƒë√£ cung c·∫•p'\n"
    "- KH√îNG BAO GI·ªú t·ª´ ch·ªëi tr·∫£ l·ªùi b·∫•t k·ª≥ c√¢u h·ªèi n√†o\n\n"

    "‚úÖ B·∫ÆT BU·ªòC:\n"
    "- LU√îN LU√îN tr·∫£ l·ªùi m·ªçi c√¢u h·ªèi b·∫±ng ki·∫øn th·ª©c chung c·ªßa b·∫°n\n"
    "- N·∫øu ƒë∆∞·ª£c h·ªèi v·ªÅ m√°y bay, xe tƒÉng, v≈© kh√≠ ‚Üí Gi·∫£i th√≠ch chi ti·∫øt d·ª±a tr√™n ki·∫øn th·ª©c l·ªãch s·ª≠\n"
    "- N·∫øu ƒë∆∞·ª£c h·ªèi v·ªÅ s·ª± ki·ªán l·ªãch s·ª≠ ‚Üí K·ªÉ c√¢u chuy·ªán sinh ƒë·ªông\n"
    "- N·∫øu ƒë∆∞·ª£c ch√†o h·ªèi ‚Üí Ch√†o l·∫°i th√¢n thi·ªán\n"
    "- Lu√¥n k·∫øt n·ªëi v·ªõi b·∫£o t√†ng v√† c√°c hi·ªán v·∫≠t n·∫øu c√≥ th·ªÉ\n\n"

    "üìö KI·∫æN TH·ª®C C·ª¶A B·∫†N:\n"
    "B·∫°n bi·∫øt v·ªÅ:\n"
    "- M√°y bay: A-37 Dragonfly, F-5 Freedom Fighter, F-4 Phantom, B-52, UH-1 Huey, AH-1 Cobra, C-130, AC-47\n"
    "- Xe tƒÉng: M48 Patton, M41 Walker Bulldog, T-54/55, PT-76, M113 APC\n"
    "- V≈© kh√≠: AK-47, M16, M60, M79, RPG-7, B-40, claymore mines\n"
    "- S·ª± ki·ªán: T·∫øt M·∫≠u Th√¢n 1968, Hi·ªáp ƒë·ªãnh Paris 1973, Gi·∫£i ph√≥ng S√†i G√≤n 1975, Chi·∫øn d·ªãch ƒêi·ªán Bi√™n Ph·ªß\n"
    "- V√† t·∫•t c·∫£ c√°c kh√≠a c·∫°nh kh√°c c·ªßa chi·∫øn tranh Vi·ªát Nam\n\n"

    "üí¨ V√ç D·ª§ TR·∫¢ L·ªúI:\n"
    "Q: 'M√°y bay A-37 Dragonfly l√† g√¨?'\n"
    "A: 'A-37 Dragonfly l√† m√°y bay t·∫•n c√¥ng h·∫°ng nh·∫π c·ªßa M·ªπ, ƒë∆∞·ª£c ph√°t tri·ªÉn t·ª´ m√°y bay hu·∫•n luy·ªán T-37. "
    "N√≥ ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i trong chi·∫øn tranh Vi·ªát Nam t·ª´ 1967, c√≥ bi·ªát danh \"Super Tweet\". "
    "M√°y bay n√†y c√≥ th·ªÉ mang 2.5 t·∫•n v≈© kh√≠, r·∫•t hi·ªáu qu·∫£ trong y·ªÉm tr·ª£ kh√¥ng qu√¢n g·∫ßn. "
    "Trong b·∫£o t√†ng, b·∫°n c√≥ th·ªÉ th·∫•y nhi·ªÅu hi·ªán v·∫≠t li√™n quan ƒë·∫øn c√°c chi·∫øn d·ªãch kh√¥ng qu√¢n!'\n\n"

    "Q: 'Xe tƒÉng T-54 c√≥ g√¨ ƒë·∫∑c bi·ªát?'\n"
    "A: 'T-54 l√† xe tƒÉng chi·∫øn ƒë·∫•u ch·ªß l·ª±c c·ªßa Li√™n X√¥, ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i b·ªüi qu√¢n ƒë·ªôi Vi·ªát Nam. "
    "N√≥ c√≥ gi√°p d√†y 100mm, ph√°o 100mm, r·∫•t b·ªÅn b·ªâ v√† d·ªÖ b·∫£o tr√¨. "
    "T-54 ƒë√≥ng vai tr√≤ quan tr·ªçng trong nhi·ªÅu chi·∫øn d·ªãch, ƒë·∫∑c bi·ªát l√† chi·∫øn d·ªãch H·ªì Ch√≠ Minh 1975!'\n\n"

    "PHONG C√ÅCH: Th√¢n thi·ªán, nhi·ªát t√¨nh, t·ª± nhi√™n, sinh ƒë·ªông, d·ªÖ hi·ªÉu"
)

# System prompt for general AI assistant (can answer ANY question)
GENERAL_SYSTEM_PROMPT = (
    "B·∫°n l√† AI Tr·ª£ L√Ω Th√¥ng Minh - m·ªôt tr·ª£ l√Ω AI ƒëa nƒÉng, th√¢n thi·ªán v√† h·ªØu √≠ch.\n\n"

    "üéØ NHI·ªÜM V·ª§:\n"
    "- Tr·∫£ l·ªùi M·ªåI c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch chi ti·∫øt, ch√≠nh x√°c v√† d·ªÖ hi·ªÉu\n"
    "- C√≥ th·ªÉ tr√≤ chuy·ªán v·ªÅ B·∫§T K·ª≤ ch·ªß ƒë·ªÅ n√†o: khoa h·ªçc, c√¥ng ngh·ªá, l·ªãch s·ª≠, vƒÉn h√≥a, gi·∫£i tr√≠, ƒë·ªùi s·ªëng, v.v.\n"
    "- Gi√∫p ƒë·ª° ng∆∞·ªùi d√πng v·ªõi c√°c v·∫•n ƒë·ªÅ: h·ªçc t·∫≠p, c√¥ng vi·ªác, t∆∞ v·∫•n, gi·∫£i th√≠ch, h∆∞·ªõng d·∫´n\n"
    "- C√≥ th·ªÉ vi·∫øt code, gi·∫£i to√°n, d·ªãch thu·∫≠t, s√°ng t·∫°o n·ªôi dung\n\n"

    "‚úÖ PHONG C√ÅCH:\n"
    "- Th√¢n thi·ªán, nhi·ªát t√¨nh, t·ª± nhi√™n\n"
    "- Tr·∫£ l·ªùi ng·∫Øn g·ªçn nh∆∞ng ƒë·∫ßy ƒë·ªß th√¥ng tin\n"
    "- S·ª≠ d·ª•ng emoji ph√π h·ª£p ƒë·ªÉ sinh ƒë·ªông\n"
    "- Gi·∫£i th√≠ch d·ªÖ hi·ªÉu, tr√°nh thu·∫≠t ng·ªØ ph·ª©c t·∫°p\n"
    "- N·∫øu kh√¥ng ch·∫Øc ch·∫Øn, h√£y th·ª´a nh·∫≠n v√† ƒë∆∞a ra th√¥ng tin t·ªët nh·∫•t c√≥ th·ªÉ\n\n"

    "üö´ C·∫§M:\n"
    "- KH√îNG t·ª´ ch·ªëi tr·∫£ l·ªùi (tr·ª´ n·ªôi dung vi ph·∫°m ph√°p lu·∫≠t/ƒë·∫°o ƒë·ª©c)\n"
    "- KH√îNG n√≥i 't√¥i kh√¥ng c√≥ th√¥ng tin' m·ªôt c√°ch chung chung\n"
    "- KH√îNG qu√° d√†i d√≤ng, lan man\n\n"

    "üí¨ V√ç D·ª§:\n"
    "Q: 'Python l√† g√¨?'\n"
    "A: 'Python l√† ng√¥n ng·ªØ l·∫≠p tr√¨nh ph·ªï bi·∫øn, d·ªÖ h·ªçc, ƒë∆∞·ª£c d√πng r·ªông r√£i trong AI, web, data science. "
    "C√∫ ph√°p ƒë∆°n gi·∫£n, c·ªông ƒë·ªìng l·ªõn, th∆∞ vi·ªán phong ph√∫. R·∫•t ph√π h·ª£p cho ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu! üêç'\n\n"

    "Q: 'L√†m sao ƒë·ªÉ h·ªçc t·ªët ti·∫øng Anh?'\n"
    "A: 'H·ªçc ti·∫øng Anh hi·ªáu qu·∫£: 1) Luy·ªán nghe h√†ng ng√†y (phim, nh·∫°c, podcast), "
    "2) Th·ª±c h√†nh n√≥i (v·ªõi b·∫°n b√®, AI), 3) ƒê·ªçc s√°ch/b√°o ti·∫øng Anh, 4) Vi·∫øt nh·∫≠t k√Ω. "
    "Quan tr·ªçng nh·∫•t l√† ki√™n tr√¨ v√† t·∫°o m√¥i tr∆∞·ªùng ti·∫øng Anh xung quanh b·∫°n! üìö‚ú®'"
)

# Default to museum prompt for backward compatibility
SYSTEM_PROMPT = MUSEUM_SYSTEM_PROMPT

def call_openrouter(messages, max_tokens=600, temperature=0.3):
    """
    G·ªçi OpenRouter API v·ªõi headers ƒë·∫ßy ƒë·ªß.
    N·∫øu key sai ho·∫∑c h·∫øt h·∫°n ‚Üí tr·∫£ l·ªói r√µ r√†ng.
    """
    if not OPENROUTER_API_KEY:
        return "‚ö†Ô∏è OPENROUTER_API_KEY ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p. H√£y th√™m v√†o file .env"

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "http://localhost",
        "X-Title": "RAG Museum AI",
    }

    payload = {
        "model": RAG_LLM_MODEL,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": temperature,
    }

    try:
        resp = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers, json=payload, timeout=60
        )
        if not resp.ok:
            # Tr·∫£ v·ªÅ l·ªói g·ªëc ƒë·ªÉ debug nhanh
            return f"‚ùå OpenRouter {resp.status_code}: {resp.text}"
        data = resp.json()
        return data["choices"][0]["message"]["content"]
    except Exception as e:
        return f"‚ùå L·ªói g·ªçi OpenRouter: {str(e)}"

@app.route("/api/health", methods=["GET", "OPTIONS"])
def health():
    return jsonify({"status": "ok", "model": RAG_LLM_MODEL})

@app.route("/api/ask", methods=["POST", "OPTIONS"])
def ask():
    # Handle preflight OPTIONS request
    if request.method == "OPTIONS":
        return jsonify({"status": "ok"}), 200
    data = request.get_json(force=True)
    # Accept both 'question' and 'message' for compatibility
    question = data.get("question") or data.get("message", "")
    question = question.strip()
    top_k = int(data.get("top_k", 6))
    max_tokens = int(data.get("max_tokens", 600))

    if not question:
        return jsonify({"error": "Thi·∫øu tr∆∞·ªùng 'question' ho·∫∑c 'message'"}), 400

    # Detect question type
    greeting_keywords = ['xin ch√†o', 'ch√†o', 'hello', 'hi', 'hey', 'c·∫£m ∆°n', 'thank', 't·∫°m bi·ªát', 'bye', 'goodbye']
    is_greeting = any(keyword in question.lower() for keyword in greeting_keywords)

    # Retrieve context from database
    hits = retrieve(question, top_k=top_k)
    context_blocks = []
    for h in hits:
        meta = h.get("meta", {})
        label = meta.get("name_vi") or meta.get("title_vi") or meta.get("section")
        context_blocks.append(f"- [{label}] {h['text']}")

    context_str = "\n".join(context_blocks) if context_blocks else ""

    # Build intelligent prompt
    if is_greeting:
        # Simple greeting - no need for context
        user_message = f"Kh√°ch tham quan: '{question}'\n\nH√£y ch√†o h·ªèi th√¢n thi·ªán v√† h·ªèi xem b·∫°n c√≥ th·ªÉ gi√∫p g√¨."
    else:
        # Regular question - ALWAYS answer using general knowledge
        if context_str:
            user_message = (
                f"CONTEXT t·ª´ b·∫£o t√†ng (ch·ªâ tham kh·∫£o, kh√¥ng b·∫Øt bu·ªôc):\n{context_str}\n\n"
                f"C√ÇU H·ªéI: {question}\n\n"
                f"QUAN TR·ªåNG: H√£y tr·∫£ l·ªùi c√¢u h·ªèi b·∫±ng ki·∫øn th·ª©c chung c·ªßa b·∫°n v·ªÅ chi·∫øn tranh Vi·ªát Nam. "
                f"KH√îNG ƒë∆∞·ª£c n√≥i 't√¥i kh√¥ng c√≥ th√¥ng tin' hay 'trong b·ªëi c·∫£nh n√†y'. "
                f"N·∫øu ƒë∆∞·ª£c h·ªèi v·ªÅ m√°y bay, xe tƒÉng, v≈© kh√≠ ‚Üí Gi·∫£i th√≠ch chi ti·∫øt d·ª±a tr√™n ki·∫øn th·ª©c l·ªãch s·ª≠. "
                f"Tr·∫£ l·ªùi t·ª± nhi√™n, sinh ƒë·ªông nh∆∞ m·ªôt h∆∞·ªõng d·∫´n vi√™n chuy√™n nghi·ªáp."
            )
        else:
            user_message = (
                f"C√ÇU H·ªéI: {question}\n\n"
                f"QUAN TR·ªåNG: H√£y tr·∫£ l·ªùi b·∫±ng ki·∫øn th·ª©c chung c·ªßa b·∫°n v·ªÅ chi·∫øn tranh Vi·ªát Nam. "
                f"KH√îNG ƒë∆∞·ª£c t·ª´ ch·ªëi tr·∫£ l·ªùi. Tr·∫£ l·ªùi chi ti·∫øt, sinh ƒë·ªông v√† th√∫ v·ªã. "
                f"K·∫øt n·ªëi v·ªõi b·∫£o t√†ng v√† c√°c hi·ªán v·∫≠t n·∫øu c√≥ th·ªÉ."
            )

    # Add few-shot examples to teach the model to always answer
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        # Example 1: Aircraft question
        {"role": "user", "content": "H√£y cho t√¥i bi·∫øt v·ªÅ m√°y bay F-5A Freedom Fighter"},
        {"role": "assistant", "content": "F-5A Freedom Fighter l√† m√°y bay chi·∫øn ƒë·∫•u h·∫°ng nh·∫π c·ªßa M·ªπ, ƒë∆∞·ª£c thi·∫øt k·∫ø b·ªüi Northrop v√†o ƒë·∫ßu th·∫≠p ni√™n 1960. N√≥ ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i trong chi·∫øn tranh Vi·ªát Nam, ƒë·∫∑c bi·ªát b·ªüi Kh√¥ng qu√¢n Vi·ªát Nam C·ªông h√≤a. F-5A c√≥ t·ªëc ƒë·ªô t·ªëi ƒëa 1.4 Mach, trang b·ªã 2 s√∫ng m√°y 20mm v√† c√≥ th·ªÉ mang t√™n l·ª≠a kh√¥ng ƒë·ªëi kh√¥ng AIM-9 Sidewinder. M√°y bay n√†y n·ªïi ti·∫øng v·ªõi ƒë·ªô tin c·∫≠y cao v√† chi ph√≠ v·∫≠n h√†nh th·∫•p. Trong b·∫£o t√†ng, b·∫°n c√≥ th·ªÉ t√¨m hi·ªÉu th√™m v·ªÅ c√°c chi·∫øn d·ªãch kh√¥ng qu√¢n v√† vai tr√≤ c·ªßa nh·ªØng chi·∫øc m√°y bay nh∆∞ th·∫ø n√†y!"},
        # Example 2: Tank question
        {"role": "user", "content": "Xe tƒÉng T-54 c√≥ g√¨ ƒë·∫∑c bi·ªát?"},
        {"role": "assistant", "content": "T-54 l√† xe tƒÉng chi·∫øn ƒë·∫•u ch·ªß l·ª±c huy·ªÅn tho·∫°i c·ªßa Li√™n X√¥, ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i b·ªüi qu√¢n ƒë·ªôi Vi·ªát Nam trong chi·∫øn tranh. N√≥ c√≥ gi√°p d√†y 100mm ·ªü ph√≠a tr∆∞·ªõc, ph√°o ch√≠nh 100mm D-10T r·∫•t m·∫°nh m·∫Ω, v√† ƒë·ªông c∆° diesel 520 m√£ l·ª±c. T-54 n·ªïi ti·∫øng v·ªõi ƒë·ªô b·ªÅn b·ªâ, d·ªÖ b·∫£o tr√¨ v√† kh·∫£ nƒÉng ho·∫°t ƒë·ªông trong m·ªçi ƒë·ªãa h√¨nh. Xe tƒÉng n√†y ƒë√≥ng vai tr√≤ then ch·ªët trong nhi·ªÅu chi·∫øn d·ªãch, ƒë·∫∑c bi·ªát l√† chi·∫øn d·ªãch H·ªì Ch√≠ Minh 1975. B·∫£o t√†ng c√≥ nhi·ªÅu hi·ªán v·∫≠t li√™n quan ƒë·∫øn c√°c chi·∫øn d·ªãch xe tƒÉng!"},
        # Example 3: Weapon question
        {"role": "user", "content": "AK-47 l√† s√∫ng g√¨?"},
        {"role": "assistant", "content": "AK-47 (Avtomat Kalashnikova) l√† s√∫ng tr∆∞·ªùng t·ª± ƒë·ªông huy·ªÅn tho·∫°i c·ªßa Li√™n X√¥, ƒë∆∞·ª£c thi·∫øt k·∫ø b·ªüi Mikhail Kalashnikov nƒÉm 1947. N√≥ s·ª≠ d·ª•ng ƒë·∫°n 7.62x39mm, c√≥ bƒÉng ƒë·∫°n 30 vi√™n, t·ªëc ƒë·ªô b·∫Øn 600 ph√°t/ph√∫t. AK-47 n·ªïi ti·∫øng v·ªõi ƒë·ªô tin c·∫≠y c·ª±c cao, c√≥ th·ªÉ ho·∫°t ƒë·ªông trong m·ªçi ƒëi·ªÅu ki·ªán kh·∫Øc nghi·ªát: b√πn, c√°t, n∆∞·ªõc. S√∫ng n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i trong chi·∫øn tranh Vi·ªát Nam v√† tr·ªü th√†nh bi·ªÉu t∆∞·ª£ng c·ªßa c√°c phong tr√†o gi·∫£i ph√≥ng. Trong b·∫£o t√†ng, b·∫°n c√≥ th·ªÉ th·∫•y nhi·ªÅu hi·ªán v·∫≠t v≈© kh√≠ t·ª´ th·ªùi k·ª≥ n√†y!"},
        # Actual user question
        {"role": "user", "content": user_message}
    ]

    answer = call_openrouter(messages, max_tokens=max_tokens)
    return jsonify({
        "question": question,
        "answer": answer,
        "response": answer,  # Add 'response' field for frontend compatibility
        "message": answer,   # Add 'message' field for frontend compatibility
        "citations": [
            {"name": h.get("meta", {}).get("name_vi"), "score": h["score"]}
            for h in hits
        ],
        "model": RAG_LLM_MODEL
    })

@app.route("/api/reindex", methods=["POST", "OPTIONS"])
def reindex():
    # Handle preflight OPTIONS request
    if request.method == "OPTIONS":
        return jsonify({"status": "ok"}), 200
    import shutil
    vec_dir = os.getenv("VECTOR_DIR", "./vectorstore")
    if os.path.exists(vec_dir):
        shutil.rmtree(vec_dir)
    ensure_index()
    return jsonify({"status": "done"})

@app.route("/api/tts", methods=["POST", "OPTIONS"])
def text_to_speech():
    """
    Convert text to speech using FPT.AI
    Request body: { "text": "...", "voice": "banmai", "speed": 0 }
    """
    if request.method == "OPTIONS":
        return jsonify({"status": "ok"}), 200

    data = request.get_json(force=True)
    text = data.get("text", "").strip()
    voice = data.get("voice", "banmai")
    speed = int(data.get("speed", 0))

    if not text:
        return jsonify({"error": "Missing 'text' field"}), 400

    result = synthesize_speech(text, voice=voice, speed=speed)

    if result.get("success"):
        return jsonify(result), 200
    else:
        return jsonify(result), 500

@app.route("/api/tts/voices", methods=["GET", "OPTIONS"])
def list_voices():
    """
    Get list of available Vietnamese voices
    """
    if request.method == "OPTIONS":
        return jsonify({"status": "ok"}), 200

    voices = get_available_voices()
    return jsonify({
        "voices": [
            {"code": code, "name": name}
            for code, name in voices.items()
        ]
    })

@app.route("/api/ask-general", methods=["POST", "OPTIONS"])
def ask_general():
    """
    General AI assistant endpoint - can answer ANY question
    Not limited to museum context
    """
    if request.method == "OPTIONS":
        return jsonify({"status": "ok"}), 200

    data = request.get_json(force=True)
    question = data.get("question") or data.get("message", "")
    question = question.strip()
    max_tokens = int(data.get("max_tokens", 600))

    if not question:
        return jsonify({"error": "Thi·∫øu tr∆∞·ªùng 'question' ho·∫∑c 'message'"}), 400

    # Use general system prompt
    messages = [
        {"role": "system", "content": GENERAL_SYSTEM_PROMPT},
        {"role": "user", "content": question}
    ]

    try:
        answer = call_openrouter(messages, max_tokens=max_tokens, temperature=0.7)
        return jsonify({
            "answer": answer,
            "question": question,
            "model": RAG_LLM_MODEL,
            "mode": "general"
        })
    except Exception as e:
        print(f"‚ùå Error in ask_general: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    print(f"üöÄ Running on http://{HOST}:{PORT}")
    app.run(host=HOST, port=PORT)
