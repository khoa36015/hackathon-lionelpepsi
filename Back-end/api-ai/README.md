
# RAG Museum AI (War Remnants Museum) â€” Complete Project

A ready-to-run **Retrieval-Augmented Generation (RAG)** API that reads the bilingual training dataset
and answers questions grounded in the JSON content.

## Features
- ğŸ” Local embeddings with `sentence-transformers`
- ğŸ“š Retrieval over timeline, artifacts, witnesses, reflections
- ğŸ¤– Generation via **OpenRouter** (set your API key)
- ğŸŒ Flask API + CORS + simple Web demo (`index.html`)
- ğŸ³ Docker & docker-compose included

## Project Structure
```
rag_museum_ai/
â”œâ”€â”€ app.py                  # Flask API
â”œâ”€â”€ rag_core.py             # RAG logic: chunk â†’ embed â†’ retrieve
â”œâ”€â”€ data/
â”‚   â””â”€â”€ war_remnants_ai_training_v3.json
â”œâ”€â”€ vectorstore/            # auto-generated embeddings
â”œâ”€â”€ index.html              # simple web tester
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ README.md
â”œâ”€â”€ Dockerfile
â””â”€â”€ docker-compose.yml
```

## 1) Local Run
```bash
cd rag_museum_ai
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
cp .env.example .env
# Edit .env â†’ add your OPENROUTER_API_KEY and model if needed
python app.py
```

### Test
```bash
curl -X POST http://localhost:8000/api/ask   -H "Content-Type: application/json"   -d '{"question":"Ká»ƒ cÃ¢u chuyá»‡n vá» bá»©c áº£nh Em bÃ© Napalm"}'
```

## 2) Docker
```bash
cd rag_museum_ai
docker build -t rag-museum-ai:latest .
docker run -p 8000:8000 --env-file .env rag-museum-ai:latest
```
Or with compose:
```bash
docker-compose up --build
```

## 3) API Endpoints
- `GET /api/health` â†’ model status
- `POST /api/ask` â†’ `{ "question": "...", "top_k": 6, "max_tokens": 500 }`
- `POST /api/reindex` â†’ rebuild embeddings after you edit the dataset

## 4) Environment (.env)
```
OPENROUTER_API_KEY=sk-or-your-key
RAG_LLM_MODEL=openai/gpt-4o-mini
DATASET_PATH=./data/war_remnants_ai_training_v3.json
HOST=0.0.0.0
PORT=8000
```

## 5) Troubleshooting
- If you see: `OPENROUTER_API_KEY is missing` â†’ check `.env`
- Slow first response? It may be building the embedding index (`vectorstore/`).
- Change embedding model: set `EMB_MODEL` env: `sentence-transformers/all-MiniLM-L6-v2` (default).

## 6) Security Notes
- This project avoids political advocacy; answers are grounded in dataset content.
- Consider rate limiting and input size checks for production.

Enjoy!
